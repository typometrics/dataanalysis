{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d8c302b",
   "metadata": {},
   "source": [
    "# 2. Metric Computation (Core Analysis)\n",
    "\n",
    "**Summary**: The main computational workhorse. Calculates dependency sizes, bastard statistics, VO/HI scores, and sentence disorder metrics using parallel processing.\n",
    "\n",
    "**Key Steps**:\n",
    "1. Load metadata and short CoNLL files.\n",
    "2. Parallel Processing: Compute dependency size stats, bastard counts, and VO/HI scores for all languages.\n",
    "3. (Optional) Compute sentence-level disorder statistics.\n",
    "4. Filter results by minimum occurrence count.\n",
    "\n",
    "**Inputs**:\n",
    "- `2.17_short/` (Short CoNLL files)\n",
    "- `data/metadata.pkl`\n",
    "\n",
    "**Outputs**:\n",
    "- `data/all_langs_position2num.pkl` (Counts)\n",
    "- `data/all_langs_average_sizes.pkl` (Geometric means)\n",
    "- `data/vo_vs_hi_scores.csv`\n",
    "- `data/sentence_disorder_percentages.pkl`\n",
    "\n",
    "**Runtime**: ~2-5 minutes (parallelized)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f1f0fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import custom modules\n",
    "import data_utils\n",
    "import conll_processing\n",
    "import analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b66220a",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b63a2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data\"\n",
    "MIN_COUNT = 10  # Minimum occurrence count for positions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d125414d",
   "metadata": {},
   "source": [
    "## 1. Load Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54ea090a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded metadata from data/metadata.pkl\n",
      "UD version: 2.17\n",
      "Languages: 187\n",
      "Total short files to process: 810\n"
     ]
    }
   ],
   "source": [
    "# Load metadata from notebook 01\n",
    "metadata = data_utils.load_metadata(os.path.join(DATA_DIR, 'metadata.pkl'))\n",
    "\n",
    "langShortConllFiles = metadata['langShortConllFiles']\n",
    "langNames = metadata['langNames']\n",
    "langnameGroup = metadata['langnameGroup']\n",
    "appearance_dict = metadata['appearance_dict']\n",
    "ud_version = metadata['ud_version']\n",
    "\n",
    "print(f\"UD version: {ud_version}\")\n",
    "print(f\"Languages: {len(langShortConllFiles)}\")\n",
    "total_files = sum(len(files) for files in langShortConllFiles.values())\n",
    "print(f\"Total short files to process: {total_files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70be9a3",
   "metadata": {},
   "source": [
    "## 2. Process CoNLL Files in Parallel\n",
    "\n",
    "This step extracts dependency sizes for all verbal constructions across all languages.\n",
    "It uses multiprocessing to parallelize across CPU cores.\n",
    "\n",
    "**Note**: This is the most computationally intensive step and may take a long time depending on your system. On Calcul, this takes less than 40 seconds without bastards, and about 1 min 15 seconds with bastards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cc815da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 810 files in parallel...\n"
     ]
    }
   ],
   "source": [
    "# Flatten all short files into a single list\n",
    "allshortconll = []\n",
    "for lang, files in langShortConllFiles.items():\n",
    "    allshortconll.extend(files)\n",
    "\n",
    "print(f\"Processing {len(allshortconll)} files in parallel...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bef6076e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting unified analysis (Dependencies, Bastards, VO/HI, Disorder). this should take about a minute on 80 cores...\n",
      "Starting unified processing on 80 cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 810/810 [01:06<00:00, 12.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing. Combining results...\n",
      "Done!\n",
      "Collected configuration examples for 186 languages\n",
      "Processing complete!\n",
      "Results computed for 186 languages\n",
      "Saved VO/HI scores to data/vo_vs_hi_scores.csv\n",
      "Saved configuration examples to data/all_config_examples.pkl\n",
      "Bastard stats also computed.\n"
     ]
    }
   ],
   "source": [
    "# Unified processing: Compute ALL metrics in one pass\n",
    "import importlib\n",
    "importlib.reload(conll_processing)\n",
    "\n",
    "print(\"Starting unified analysis (Dependencies, Bastards, VO/HI, Disorder). this should take about a minute on 80 cores...\")\n",
    "\n",
    "# Allow configuring sentence disorder and configuration examples\n",
    "compute_sentence_disorder = True\n",
    "collect_config_examples = True  # Collect examples for HTML visualization\n",
    "\n",
    "results = conll_processing.get_all_stats_parallel(\n",
    "    allshortconll,\n",
    "    include_bastards=True,\n",
    "    compute_sentence_disorder=compute_sentence_disorder,\n",
    "    collect_config_examples=collect_config_examples,\n",
    "    max_examples_per_config=10\n",
    ")\n",
    "\n",
    "# Unpack results\n",
    "if collect_config_examples:\n",
    "    (all_langs_position2num, all_langs_position2sizes, all_langs_average_sizes, all_langs_average_charsizes, \n",
    "     lang_bastard_stats, global_bastard_relations, \n",
    "     lang_vo_hi_scores, \n",
    "     sentence_disorder_pct,\n",
    "     all_config_examples) = results\n",
    "    print(f\"Collected configuration examples for {len(all_config_examples)} languages\")\n",
    "else:\n",
    "    (all_langs_position2num, all_langs_position2sizes, all_langs_average_sizes, all_langs_average_charsizes, \n",
    "     lang_bastard_stats, global_bastard_relations, \n",
    "     lang_vo_hi_scores, \n",
    "     sentence_disorder_pct) = results\n",
    "    all_config_examples = None\n",
    "\n",
    "print(\"Processing complete!\")\n",
    "print(f\"Results computed for {len(all_langs_position2num)} languages\")\n",
    "\n",
    "# Save VO/HI Scores immediately\n",
    "vo_hi_rows = []\n",
    "for lang, scores in lang_vo_hi_scores.items():\n",
    "    row = scores.copy()\n",
    "    row['language_code'] = lang\n",
    "    row['language_name'] = langNames.get(lang, lang)\n",
    "    row['group'] = langnameGroup.get(row['language_name'], 'Unknown')\n",
    "    vo_hi_rows.append(row)\n",
    "\n",
    "vo_hi_df = pd.DataFrame(vo_hi_rows)\n",
    "vo_hi_output_file = os.path.join(DATA_DIR, 'vo_vs_hi_scores.csv')\n",
    "vo_hi_df.to_csv(vo_hi_output_file, index=False)\n",
    "print(f\"Saved VO/HI scores to {vo_hi_output_file}\")\n",
    "\n",
    "# Save configuration examples if collected\n",
    "if all_config_examples is not None:\n",
    "    import pickle\n",
    "    config_examples_path = os.path.join(DATA_DIR, 'all_config_examples.pkl')\n",
    "    with open(config_examples_path, 'wb') as f:\n",
    "        pickle.dump(all_config_examples, f)\n",
    "    print(f\"Saved configuration examples to {config_examples_path}\")\n",
    "\n",
    "# We already have bastard stats, so no need to re-run later\n",
    "print(\"Bastard stats also computed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f637e3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VO: 93\n",
      "OV: 69\n",
      "NDO: 24\n"
     ]
    }
   ],
   "source": [
    "# In notebook 02 after running:\n",
    "print(f\"VO: {len([l for l in lang_vo_hi_scores.values() if l.get('vo_type') == 'VO'])}\")\n",
    "print(f\"OV: {len([l for l in lang_vo_hi_scores.values() if l.get('vo_type') == 'OV'])}\")\n",
    "print(f\"NDO: {len([l for l in lang_vo_hi_scores.values() if l.get('vo_type') == 'NDO'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64365da",
   "metadata": {},
   "source": [
    "## 2b. Compute Sentence-Level Disorder (Optional)\n",
    "\n",
    "this cell is useful:\n",
    "* It handles saving: The new unified processing block I added computes the data (sentence_disorder_pct), but it does not save it. This cell converts that raw data into a DataFrame and saves it to sentence_disorder_percentages.csv and .pkl.\n",
    "* It formats the data: It transforms the raw nested dictionary into a flat table structure that is needed for the subsequent notebooks.\n",
    "\n",
    "Set `compute_sentence_disorder=True` to enable this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a27d8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence-level disorder DataFrame:\n",
      "  Shape: (186, 2647)\n",
      "\n",
      "Sample:\n",
      "  language_code language_name           group  left_tot_1_total  \\\n",
      "0           abq         Abaza       Caucasian               108   \n",
      "1            ab        Abkhaz       Caucasian              1483   \n",
      "2            af     Afrikaans   Indo-European              1391   \n",
      "3           akk      Akkadian     Afroasiatic              1317   \n",
      "4           aqz       Akuntsu  South-American               180   \n",
      "\n",
      "   right_tot_1_total  left_tot_2_total  left_tot_2_pair_0_lt  \\\n",
      "0               35.0                48                    10   \n",
      "1              354.0               742                   116   \n",
      "2             1786.0              1362                   720   \n",
      "3              455.0               978                   338   \n",
      "4               82.0                52                     2   \n",
      "\n",
      "   left_tot_2_pair_0_eq  left_tot_2_pair_0_gt  left_tot_2_pair_0_total  ...  \\\n",
      "0                    19                    19                       48  ...   \n",
      "1                   351                   275                      742  ...   \n",
      "2                   323                   319                     1362  ...   \n",
      "3                   162                   478                      978  ...   \n",
      "4                    44                     6                       52  ...   \n",
      "\n",
      "   right_tot_18_pair_15_lt_pct  right_tot_18_pair_15_eq_pct  \\\n",
      "0                          NaN                          NaN   \n",
      "1                          NaN                          NaN   \n",
      "2                          NaN                          NaN   \n",
      "3                          NaN                          NaN   \n",
      "4                          NaN                          NaN   \n",
      "\n",
      "   right_tot_18_pair_15_gt_pct  right_tot_18_pair_16_lt  \\\n",
      "0                          NaN                      NaN   \n",
      "1                          NaN                      NaN   \n",
      "2                          NaN                      NaN   \n",
      "3                          NaN                      NaN   \n",
      "4                          NaN                      NaN   \n",
      "\n",
      "   right_tot_18_pair_16_eq  right_tot_18_pair_16_gt  \\\n",
      "0                      NaN                      NaN   \n",
      "1                      NaN                      NaN   \n",
      "2                      NaN                      NaN   \n",
      "3                      NaN                      NaN   \n",
      "4                      NaN                      NaN   \n",
      "\n",
      "   right_tot_18_pair_16_total  right_tot_18_pair_16_lt_pct  \\\n",
      "0                         NaN                          NaN   \n",
      "1                         NaN                          NaN   \n",
      "2                         NaN                          NaN   \n",
      "3                         NaN                          NaN   \n",
      "4                         NaN                          NaN   \n",
      "\n",
      "   right_tot_18_pair_16_eq_pct  right_tot_18_pair_16_gt_pct  \n",
      "0                          NaN                          NaN  \n",
      "1                          NaN                          NaN  \n",
      "2                          NaN                          NaN  \n",
      "3                          NaN                          NaN  \n",
      "4                          NaN                          NaN  \n",
      "\n",
      "[5 rows x 2647 columns]\n",
      "\n",
      "Saved sentence disorder data to data/\n"
     ]
    }
   ],
   "source": [
    "# Convert sentence disorder percentages to DataFrame and save\n",
    "if sentence_disorder_pct is not None:\n",
    "    import pickle\n",
    "    \n",
    "    # Convert to DataFrame format suitable for notebook 04\n",
    "    sentence_disorder_rows = []\n",
    "    for lang_code in sentence_disorder_pct:\n",
    "        lang_name = langNames.get(lang_code, lang_code)\n",
    "        group = langnameGroup.get(lang_name, 'Unknown')\n",
    "        \n",
    "        row = {\n",
    "            'language_code': lang_code,\n",
    "            'language_name': lang_name,\n",
    "            'group': group\n",
    "        }\n",
    "        \n",
    "        # Add columns for each configuration\n",
    "        # Process granular ordering stats\n",
    "        # Key is now (side, tot, pair_idx)\n",
    "        for (side, tot, idx), counts in sentence_disorder_pct[lang_code].items():\n",
    "            if isinstance(counts, int):\n",
    "                # Handle integer total counts\n",
    "                row[f'{side}_tot_{tot}_{idx}'] = counts\n",
    "                continue\n",
    "            \n",
    "            total = counts['lt'] + counts['eq'] + counts['gt']\n",
    "            \n",
    "            prefix = f'{side}_tot_{tot}_pair_{idx}'\n",
    "            row[f'{prefix}_lt'] = counts['lt']\n",
    "            row[f'{prefix}_eq'] = counts['eq']\n",
    "            row[f'{prefix}_gt'] = counts['gt']\n",
    "            row[f'{prefix}_total'] = total\n",
    "            \n",
    "            if total > 0:\n",
    "                row[f'{prefix}_lt_pct'] = counts['lt'] / total * 100\n",
    "                row[f'{prefix}_eq_pct'] = counts['eq'] / total * 100\n",
    "                row[f'{prefix}_gt_pct'] = counts['gt'] / total * 100\n",
    "            else:\n",
    "                row[f'{prefix}_lt_pct'] = 0\n",
    "                row[f'{prefix}_eq_pct'] = 0\n",
    "                row[f'{prefix}_gt_pct'] = 0\n",
    "        \n",
    "        sentence_disorder_rows.append(row)\n",
    "    \n",
    "    sentence_disorder_df = pd.DataFrame(sentence_disorder_rows)\n",
    "    \n",
    "    print(f\"\\nSentence-level disorder DataFrame:\")\n",
    "    print(f\"  Shape: {sentence_disorder_df.shape}\")\n",
    "    # print(f\"  Columns: {list(sentence_disorder_df.columns)}\")\n",
    "    print(\"\\nSample:\")\n",
    "    print(sentence_disorder_df.head())\n",
    "    \n",
    "    # Save to pickle and CSV\n",
    "    with open(os.path.join(DATA_DIR, 'sentence_disorder_percentages.pkl'), 'wb') as f:\n",
    "        pickle.dump(sentence_disorder_pct, f)\n",
    "    \n",
    "    sentence_disorder_df.to_csv(os.path.join(DATA_DIR, 'sentence_disorder_percentages.csv'), index=False)\n",
    "    \n",
    "    print(f\"\\nSaved sentence disorder data to {DATA_DIR}/\")\n",
    "else:\n",
    "    print(\"Sentence-level disorder not computed (compute_sentence_disorder=False)\")\n",
    "    sentence_disorder_df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d5124",
   "metadata": {},
   "source": [
    "## 3. Filter by Minimum Count\n",
    "\n",
    "Remove positions that occur fewer than MIN_COUNT times to reduce noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a05136",
   "metadata": {},
   "source": [
    "## 4. Compute Geometric Mean Aggregate Length (MAL)\n",
    "\n",
    "For each language, compute MALₙ for n=1 to max available right dependents.\n",
    "\n",
    "We use the **Geometric Mean** to be robust against outliers in constituent length distributions.\n",
    "\n",
    "### MAL Formula\n",
    "\n",
    "$$\n",
    "\\text{MAL}_n = \\exp\\left(\\frac{\\sum_{i=1}^{n} \\text{position2sizes}[\\text{right}\\_i\\text{\\_totright}\\_n]}{\\sum_{i=1}^{n} \\text{position2num}[\\text{right}\\_i\\text{\\_totright}\\_n]}\\right)\n",
    "$$\n",
    "\n",
    "Where `position2sizes` stores the sum of logarithms of constituent sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c61136d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered to positions with at least 10 occurrences\n",
      "Positions before filtering: 22866\n",
      "Positions after filtering (>= 10): 12561\n",
      "Removed: 10305 (45.1%)\n"
     ]
    }
   ],
   "source": [
    "# Filter positions\n",
    "filtered_position2num, filtered_position2sizes = analysis.filter_by_min_count(\n",
    "    all_langs_position2num,\n",
    "    all_langs_position2sizes,\n",
    "    min_count=MIN_COUNT\n",
    ")\n",
    "\n",
    "# Count total positions before and after filtering\n",
    "total_before = sum(len(positions) for positions in all_langs_position2num.values())\n",
    "total_after = sum(len(positions) for positions in filtered_position2num.values())\n",
    "print(f\"Positions before filtering: {total_before}\")\n",
    "print(f\"Positions after filtering (>= {MIN_COUNT}): {total_after}\")\n",
    "print(f\"Removed: {total_before - total_after} ({100*(total_before - total_after)/total_before:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83efac16",
   "metadata": {},
   "source": [
    "## 5. Data Structure Documentation\n",
    "\n",
    "### all_langs_position2num\n",
    "Dictionary mapping each language code to a dictionary of position keys → occurrence counts.\n",
    "\n",
    "**Structure**: `{lang_code: {position_key: count}}`\n",
    "\n",
    "**Position keys**:\n",
    "- `left_N`: N-th dependent to the left of verb (N=1 is closest)\n",
    "- `right_N`: N-th dependent to the right of verb (N=1 is closest)\n",
    "- `left_N_totleft_M`: N-th left dependent when there are M total left dependents\n",
    "- `right_N_totright_M`: N-th right dependent when there are M total right dependents\n",
    "- `average_totleft_M`: average size across all left dependents when M total\n",
    "- `average_totright_M`: average size across all right dependents when M total\n",
    "\n",
    "**Example**:\n",
    "```python\n",
    "all_langs_position2num['en'] = {\n",
    "    'left_1': 12543,\n",
    "    'right_1': 18732,\n",
    "    'right_1_totright_2': 5234,\n",
    "    ...\n",
    "}\n",
    "```\n",
    "\n",
    "### all_langs_position2sizes\n",
    "Dictionary mapping each language code to a dictionary of position keys → **total log size** (sum of logarithms of all dependency sizes).\n",
    "\n",
    "**Structure**: `{lang_code: {position_key: total_log_size}}`\n",
    "\n",
    "**Note**: We use the logarithm of sizes to compute geometric means, which are more appropriate for the highly skewed distribution of constituent sizes.\n",
    "\n",
    "**Example**:\n",
    "```python\n",
    "all_langs_position2sizes['en'] = {\n",
    "    'left_1': 8694.5,  # Sum of logs of sizes\n",
    "    'right_1': 20576.2, \n",
    "    ...\n",
    "}\n",
    "```\n",
    "\n",
    "### all_langs_average_sizes\n",
    "Dictionary mapping each language code to a dictionary of position keys → **Geometric Mean** dependency size.\n",
    "\n",
    "**Structure**: `{lang_code: {position_key: geometric_mean_size}}`\n",
    "\n",
    "**Computation**: `geometric_mean = exp(total_log_size / count)`\n",
    "\n",
    "**Example**:\n",
    "```python\n",
    "all_langs_average_sizes['en'] = {\n",
    "    'left_1': 2.0,  # exp(8694.5 / 12543)\n",
    "    'right_1': 3.0, \n",
    "    ...\n",
    "}\n",
    "```\n",
    "\n",
    "### lang2MAL\n",
    "Dictionary mapping each language code to a dictionary of n → MALₙ values.\n",
    "\n",
    "**Structure**: `{lang_code: {n: MAL_n}}`\n",
    "\n",
    "**Computation**: For each n, compute the **Geometric Mean Aggregate Length** of right dependents from position 1 to n.\n",
    "\n",
    "**Formula**:\n",
    "$$\n",
    "\\text{MAL}_n = \\exp\\left(\\frac{\\sum_{i=1}^{n} \\text{position2sizes}[\\text{right}\\_i\\text{\\_totright}\\_n]}{\\sum_{i=1}^{n} \\text{position2num}[\\text{right}\\_i\\text{\\_totright}\\_n]}\\right)\n",
    "$$\n",
    "\n",
    "**Example**:\n",
    "```python\n",
    "lang2MAL['en'] = {\n",
    "    1: 2.5,  # GM size when 1 right dependent\n",
    "    2: 3.2,  # GM aggregate size when 2 right dependents\n",
    "    3: 3.8,  # GM aggregate size when 3 right dependents\n",
    "    ...\n",
    "}\n",
    "```\n",
    "\n",
    "**Interpretation**: MALₙ typically increases with n, indicating that having more dependents correlates with longer dependencies (Menzerath's Law or similar effects often visualized using this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7903261a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAL computed for 186 languages\n",
      "\n",
      "Sample (language 'abq'):\n",
      "{1: 1.5134613006817135}\n"
     ]
    }
   ],
   "source": [
    "# Compute MAL for each language\n",
    "lang2MAL = analysis.compute_MAL_per_language(\n",
    "    filtered_position2sizes,\n",
    "    filtered_position2num\n",
    ")\n",
    "\n",
    "print(f\"MAL computed for {len(lang2MAL)} languages\")\n",
    "\n",
    "# Show sample\n",
    "sample_lang = list(lang2MAL.keys())[0]\n",
    "print(f\"\\nSample (language '{sample_lang}'):\")\n",
    "print(lang2MAL[sample_lang])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e648760",
   "metadata": {},
   "source": [
    "## Analysis of bastard frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "201b5a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Bastard analysis integrated into main pass)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25b20326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 Languages by Bastard Frequency (per Verb):\n",
      "   Code           Language   Verbs  Bastards  Bastards_per_Verb_Pct  \\\n",
      "0   grc       AncientGreek   80843     24326              30.090422   \n",
      "1   xpg           Phrygian     234        58              24.786325   \n",
      "2    la              Latin  149655     29636              19.802880   \n",
      "3    ps             Pashto     327        63              19.266055   \n",
      "4   pro       OldProvençal    5468       895              16.367959   \n",
      "5   orv      OldEastSlavic   69895     11071              15.839473   \n",
      "6    sa           Sanskrit   40150      6230              15.516812   \n",
      "7    hu          Hungarian    3663       491              13.404313   \n",
      "8   swl        SwedishSign     611        81              13.256956   \n",
      "9   fro          OldFrench   37730      4609              12.215743   \n",
      "10  gub          Guajajára    1060       129              12.169811   \n",
      "11  hit            Hittite     213        25              11.737089   \n",
      "12   nl              Dutch   47886      5387              11.249635   \n",
      "13  got             Gothic   12755      1432              11.226970   \n",
      "14  gsw        SwissGerman    1924       215              11.174636   \n",
      "15   sl          Slovenian   34630      3807              10.993358   \n",
      "16   ur               Urdu   12695      1340              10.555337   \n",
      "17   cu  OldChurchSlavonic   41405      4295              10.373143   \n",
      "18  nds           LowSaxon    2570       259              10.077821   \n",
      "19  frm       MiddleFrench   12492      1207               9.662184   \n",
      "\n",
      "    Top_Bastard_Rel  \n",
      "0       nmod (4353)  \n",
      "1         conj (18)  \n",
      "2        acl (3835)  \n",
      "3          acl (25)  \n",
      "4         obj (160)  \n",
      "5       conj (2085)  \n",
      "6        acl (1816)  \n",
      "7         obl (119)  \n",
      "8         conj (47)  \n",
      "9         acl (954)  \n",
      "10  discourse (102)  \n",
      "11         conj (5)  \n",
      "12       acl (1002)  \n",
      "13        obl (254)  \n",
      "14         acl (52)  \n",
      "15        obl (474)  \n",
      "16        acl (428)  \n",
      "17        acl (440)  \n",
      "18        case (54)  \n",
      "19       conj (246)  \n",
      "\n",
      "Global Bastard Relation Frequencies:\n",
      "acl: 27129\n",
      "conj: 21541\n",
      "obl: 20089\n",
      "obj: 19446\n",
      "nmod: 18131\n",
      "advcl: 10830\n",
      "advmod: 10611\n",
      "mark: 10499\n",
      "det: 9310\n",
      "cc: 9174\n",
      "nsubj: 8699\n",
      "amod: 6525\n",
      "appos: 5888\n",
      "case: 5834\n",
      "expl: 4881\n",
      "ccomp: 4565\n",
      "xcomp: 3303\n",
      "parataxis: 1957\n",
      "cop: 1806\n",
      "iobj: 1586\n",
      "\n",
      "Exporting examples to data/bastard_examples...\n",
      "Exported example files for 167 languages.\n",
      "Exported detailed bastard relations to data/bastard_relations_per_lang.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# Compute bastard statistics\n",
    "# Stats already computed above. Skipping re-computation.\n",
    "# lang_bastard_stats, global_bastard_relations = ...\n",
    "\n",
    "# Create a DataFrame for ranking\n",
    "ranking_data = []\n",
    "for lang, stats in lang_bastard_stats.items():\n",
    "    verbs = stats['verbs']\n",
    "    bastards = stats['bastards']\n",
    "    percentage = (bastards / verbs * 100) if verbs > 0 else 0\n",
    "    \n",
    "    # Find most frequent relation\n",
    "    relations = stats.get('relations', {})\n",
    "    if relations:\n",
    "        top_rel = max(relations, key=relations.get)\n",
    "        top_rel_count = relations[top_rel]\n",
    "        top_rel_str = f\"{top_rel} ({top_rel_count})\"\n",
    "    else:\n",
    "        top_rel_str = \"None\"\n",
    "\n",
    "    ranking_data.append({\n",
    "        'Code': lang,\n",
    "        'Language': langNames.get(lang, lang),\n",
    "        'Verbs': verbs,\n",
    "        'Bastards': bastards,\n",
    "        'Bastards_per_Verb_Pct': percentage,\n",
    "        'Top_Bastard_Rel': top_rel_str\n",
    "    })\n",
    "\n",
    "df_ranking = pd.DataFrame(ranking_data)\n",
    "df_ranking = df_ranking.sort_values('Bastards_per_Verb_Pct', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\nTop 20 Languages by Bastard Frequency (per Verb):\")\n",
    "print(df_ranking.head(20))\n",
    "\n",
    "print(\"\\nGlobal Bastard Relation Frequencies:\")\n",
    "sorted_relations = sorted(global_bastard_relations.items(), key=lambda x: x[1], reverse=True)\n",
    "for rel, count in sorted_relations[:20]:\n",
    "    print(f\"{rel}: {count}\")\n",
    "\n",
    "# Export examples\n",
    "examples_dir = os.path.join(DATA_DIR, 'bastard_examples')\n",
    "os.makedirs(examples_dir, exist_ok=True)\n",
    "\n",
    "print(f\"\\nExporting examples to {examples_dir}...\")\n",
    "count_exported = 0\n",
    "\n",
    "for lang, stats in lang_bastard_stats.items():\n",
    "    relations = stats.get('relations', {})\n",
    "    examples = stats.get('examples', {})\n",
    "    \n",
    "    if relations and examples:\n",
    "        # Get most frequent relation\n",
    "        top_rel = max(relations, key=relations.get)\n",
    "        \n",
    "        if top_rel in examples:\n",
    "            # Create file content\n",
    "            content = f\"# Language: {lang} ({langNames.get(lang, lang)})\\n\"\n",
    "            content += f\"# Most frequent bastard relation: {top_rel}\\n\"\n",
    "            content += f\"# Total bastards with this relation: {relations[top_rel]}\\n\\n\"\n",
    "            \n",
    "            for i, tree_str in enumerate(examples[top_rel]):\n",
    "                content += f\"# Example {i+1}\\n\"\n",
    "                content += tree_str + \"\\n\"\n",
    "            \n",
    "            # Save to file\n",
    "            filename = os.path.join(examples_dir, f\"{lang}_{top_rel}_examples.conllu\")\n",
    "            with open(filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(content)\n",
    "            count_exported += 1\n",
    "\n",
    "print(f\"Exported example files for {count_exported} languages.\")\n",
    "\n",
    "# Export detailed bastard relation counts per language\n",
    "relation_counts_export = {}\n",
    "for lang, stats in lang_bastard_stats.items():\n",
    "    relation_counts_export[lang] = stats.get('relations', {})\n",
    "\n",
    "relation_export_path = os.path.join(DATA_DIR, 'bastard_relations_per_lang.json')\n",
    "with open(relation_export_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(relation_counts_export, f, indent=2)\n",
    "\n",
    "print(f\"Exported detailed bastard relations to {relation_export_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0ff9347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Languages by Bastard Frequency (per Verb):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Language</th>\n",
       "      <th>Verbs</th>\n",
       "      <th>Bastards</th>\n",
       "      <th>Bastards_per_Verb_Pct</th>\n",
       "      <th>Top_Bastard_Rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grc</td>\n",
       "      <td>AncientGreek</td>\n",
       "      <td>80843</td>\n",
       "      <td>24326</td>\n",
       "      <td>30.090422</td>\n",
       "      <td>nmod (4353)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xpg</td>\n",
       "      <td>Phrygian</td>\n",
       "      <td>234</td>\n",
       "      <td>58</td>\n",
       "      <td>24.786325</td>\n",
       "      <td>conj (18)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>la</td>\n",
       "      <td>Latin</td>\n",
       "      <td>149655</td>\n",
       "      <td>29636</td>\n",
       "      <td>19.802880</td>\n",
       "      <td>acl (3835)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ps</td>\n",
       "      <td>Pashto</td>\n",
       "      <td>327</td>\n",
       "      <td>63</td>\n",
       "      <td>19.266055</td>\n",
       "      <td>acl (25)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pro</td>\n",
       "      <td>OldProvençal</td>\n",
       "      <td>5468</td>\n",
       "      <td>895</td>\n",
       "      <td>16.367959</td>\n",
       "      <td>obj (160)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>bor</td>\n",
       "      <td>Borôro</td>\n",
       "      <td>27057</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>aii</td>\n",
       "      <td>Assyrian</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>apu</td>\n",
       "      <td>Apurinã</td>\n",
       "      <td>215</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>vep</td>\n",
       "      <td>Veps</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>az</td>\n",
       "      <td>Azerbaijani</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>186 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Code      Language   Verbs  Bastards  Bastards_per_Verb_Pct  \\\n",
       "0    grc  AncientGreek   80843     24326              30.090422   \n",
       "1    xpg      Phrygian     234        58              24.786325   \n",
       "2     la         Latin  149655     29636              19.802880   \n",
       "3     ps        Pashto     327        63              19.266055   \n",
       "4    pro  OldProvençal    5468       895              16.367959   \n",
       "..   ...           ...     ...       ...                    ...   \n",
       "181  bor        Borôro   27057         0               0.000000   \n",
       "182  aii      Assyrian      57         0               0.000000   \n",
       "183  apu       Apurinã     215         0               0.000000   \n",
       "184  vep          Veps     183         0               0.000000   \n",
       "185   az   Azerbaijani     190         0               0.000000   \n",
       "\n",
       "    Top_Bastard_Rel  \n",
       "0       nmod (4353)  \n",
       "1         conj (18)  \n",
       "2        acl (3835)  \n",
       "3          acl (25)  \n",
       "4         obj (160)  \n",
       "..              ...  \n",
       "181            None  \n",
       "182            None  \n",
       "183            None  \n",
       "184            None  \n",
       "185            None  \n",
       "\n",
       "[186 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Global Bastard Relation Frequencies:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relation</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acl</td>\n",
       "      <td>27129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>conj</td>\n",
       "      <td>21541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>obl</td>\n",
       "      <td>20089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>obj</td>\n",
       "      <td>19446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nmod</td>\n",
       "      <td>18131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>advcl</td>\n",
       "      <td>10830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>advmod</td>\n",
       "      <td>10611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mark</td>\n",
       "      <td>10499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>det</td>\n",
       "      <td>9310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cc</td>\n",
       "      <td>9174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nsubj</td>\n",
       "      <td>8699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>amod</td>\n",
       "      <td>6525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>appos</td>\n",
       "      <td>5888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>case</td>\n",
       "      <td>5834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>expl</td>\n",
       "      <td>4881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ccomp</td>\n",
       "      <td>4565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>xcomp</td>\n",
       "      <td>3303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>parataxis</td>\n",
       "      <td>1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cop</td>\n",
       "      <td>1806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>iobj</td>\n",
       "      <td>1586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>dislocated</td>\n",
       "      <td>1130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>nummod</td>\n",
       "      <td>1105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>discourse</td>\n",
       "      <td>954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>aux</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>dep</td>\n",
       "      <td>558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>csubj</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>reparandum</td>\n",
       "      <td>487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>orphan</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>vocative</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>compound</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>flat</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>fixed</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>list</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>clf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Relation  Count\n",
       "0          acl  27129\n",
       "1         conj  21541\n",
       "2          obl  20089\n",
       "3          obj  19446\n",
       "4         nmod  18131\n",
       "5        advcl  10830\n",
       "6       advmod  10611\n",
       "7         mark  10499\n",
       "8          det   9310\n",
       "9           cc   9174\n",
       "10       nsubj   8699\n",
       "11        amod   6525\n",
       "12       appos   5888\n",
       "13        case   5834\n",
       "14        expl   4881\n",
       "15       ccomp   4565\n",
       "16       xcomp   3303\n",
       "17   parataxis   1957\n",
       "18         cop   1806\n",
       "19        iobj   1586\n",
       "20  dislocated   1130\n",
       "21      nummod   1105\n",
       "22   discourse    954\n",
       "23         aux    800\n",
       "24         dep    558\n",
       "25       csubj    510\n",
       "26  reparandum    487\n",
       "27      orphan    363\n",
       "28    vocative    338\n",
       "29    compound    281\n",
       "30        flat    275\n",
       "31       fixed    153\n",
       "32        list     41\n",
       "33         clf      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved bastard statistics to data/bastard_stats.csv\n"
     ]
    }
   ],
   "source": [
    "# showing the bastard tables as df\n",
    "\n",
    "pd.set_option('display.max_rows', 50)\n",
    "\n",
    "print(\"Top Languages by Bastard Frequency (per Verb):\")\n",
    "display(df_ranking)\n",
    "\n",
    "print(\"\\nGlobal Bastard Relation Frequencies:\")\n",
    "df_global_relations = pd.DataFrame(\n",
    "    sorted(global_bastard_relations.items(), key=lambda x: x[1], reverse=True),\n",
    "    columns=['Relation', 'Count']\n",
    ")\n",
    "display(df_global_relations)\n",
    "\n",
    "# Save bastard stats to CSV for further analysis (e.g. Notebook 05)\n",
    "bastard_csv_path = os.path.join(DATA_DIR, 'bastard_stats.csv')\n",
    "df_ranking.to_csv(bastard_csv_path, index=False)\n",
    "print(f\"Saved bastard statistics to {bastard_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e950f09b",
   "metadata": {},
   "source": [
    "## 6. Export Analysis Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ea258a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all_langs_position2num.pkl\n",
      "Saved all_langs_position2sizes.pkl\n",
      "Saved all_langs_average_sizes.pkl\n",
      "Saved filtered_position2num.pkl\n",
      "Saved filtered_position2sizes.pkl\n",
      "Saved lang2MAL.pkl\n",
      "All analysis results saved to data/\n",
      "Analysis results saved to data/\n"
     ]
    }
   ],
   "source": [
    "# Save all analysis results\n",
    "analysis.save_analysis_results(\n",
    "    all_langs_position2num,\n",
    "    all_langs_position2sizes,\n",
    "    all_langs_average_sizes,\n",
    "    filtered_position2num,\n",
    "    filtered_position2sizes,\n",
    "    lang2MAL,\n",
    "    output_dir=DATA_DIR\n",
    ")\n",
    "\n",
    "print(f\"Analysis results saved to {DATA_DIR}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f214f92e",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has:\n",
    "- ✅ Loaded metadata from notebook 01\n",
    "- ✅ Processed all CoNLL files in parallel (extracted dependency sizes)\n",
    "- ✅ Filtered positions by minimum count (>= 10)\n",
    "- ✅ Computed Mean Aggregate Length (MAL) for each language\n",
    "- ✅ Exported 6 analysis result files to data/\n",
    "- ✅ Analyzed bastard frequencies and exported examples\n",
    "\n",
    "**Next step**: Run `03_visualization.ipynb` to create plots and explore results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a98a7c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af4d03a0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2368dca2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragenv",
   "language": "python",
   "name": "ragenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
