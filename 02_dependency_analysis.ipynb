{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "97dabcb5",
            "metadata": {},
            "source": [
                "## Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "2f1f0fad",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import pandas as pd\n",
                "from tqdm import tqdm\n",
                "\n",
                "# Import custom modules\n",
                "import data_utils\n",
                "import conll_processing\n",
                "import analysis"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2b66220a",
            "metadata": {},
            "source": [
                "## Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "3b63a2de",
            "metadata": {},
            "outputs": [],
            "source": [
                "DATA_DIR = \"data\"\n",
                "MIN_COUNT = 10  # Minimum occurrence count for positions"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d125414d",
            "metadata": {},
            "source": [
                "## 1. Load Metadata"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "54ea090a",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded metadata from data/metadata.pkl\n",
                        "UD version: 2.17\n",
                        "Languages: 186\n",
                        "Total short files to process: 818\n"
                    ]
                }
            ],
            "source": [
                "# Load metadata from notebook 01\n",
                "metadata = data_utils.load_metadata(os.path.join(DATA_DIR, 'metadata.pkl'))\n",
                "\n",
                "langShortConllFiles = metadata['langShortConllFiles']\n",
                "langNames = metadata['langNames']\n",
                "langnameGroup = metadata['langnameGroup']\n",
                "appearance_dict = metadata['appearance_dict']\n",
                "ud_version = metadata['ud_version']\n",
                "\n",
                "print(f\"UD version: {ud_version}\")\n",
                "print(f\"Languages: {len(langShortConllFiles)}\")\n",
                "total_files = sum(len(files) for files in langShortConllFiles.values())\n",
                "print(f\"Total short files to process: {total_files}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e70be9a3",
            "metadata": {},
            "source": [
                "## 2. Process CoNLL Files in Parallel\n",
                "\n",
                "This step extracts dependency sizes for all verbal constructions across all languages.\n",
                "It uses multiprocessing to parallelize across CPU cores.\n",
                "\n",
                "**Note**: This is the most computationally intensive step and may take a long time depending on your system. On Calcul, this takes less than 40 seconds without bastards, and about 1 min 15 seconds with bastards."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "0cc815da",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Processing 818 files in parallel...\n"
                    ]
                }
            ],
            "source": [
                "# Flatten all short files into a single list\n",
                "allshortconll = []\n",
                "for lang, files in langShortConllFiles.items():\n",
                "    allshortconll.extend(files)\n",
                "\n",
                "print(f\"Processing {len(allshortconll)} files in parallel...\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "bef6076e",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Starting unified analysis (Dependencies, Bastards, VO/HI, Disorder)...\n",
                        "Starting unified processing on 80 cores\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Processing files: 100%|██████████| 818/818 [00:51<00:00, 15.76it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Finished processing. Combining results...\n",
                        "Done!\n",
                        "Processing complete!\n",
                        "Results computed for 185 languages\n",
                        "Saved VO/HI scores to data/vo_vs_hi_scores.csv\n",
                        "Bastard stats also computed.\n"
                    ]
                }
            ],
            "source": [
                "import importlib\n",
                "importlib.reload(conll_processing)\n",
                "\n",
                "# Unified processing: Compute ALL metrics in one pass\n",
                "print(\"Starting unified analysis (Dependencies, Bastards, VO/HI, Disorder)...\")\n",
                "\n",
                "# Allow configuring sentence disorder\n",
                "compute_sentence_disorder = True\n",
                "\n",
                "results = conll_processing.get_all_stats_parallel(\n",
                "    allshortconll,\n",
                "    include_bastards=True,\n",
                "    compute_sentence_disorder=compute_sentence_disorder\n",
                ")\n",
                "\n",
                "# Unpack results\n",
                "(all_langs_position2num, all_langs_position2sizes, all_langs_average_sizes, \n",
                " lang_bastard_stats, global_bastard_relations, \n",
                " lang_vo_hi_scores, \n",
                " sentence_disorder_pct) = results\n",
                "\n",
                "print(\"Processing complete!\")\n",
                "print(f\"Results computed for {len(all_langs_position2num)} languages\")\n",
                "\n",
                "# Save VO/HI Scores immediately\n",
                "vo_hi_rows = []\n",
                "for lang, scores in lang_vo_hi_scores.items():\n",
                "    row = scores.copy()\n",
                "    row['language_code'] = lang\n",
                "    row['language_name'] = langNames.get(lang, lang)\n",
                "    row['group'] = langnameGroup.get(row['language_name'], 'Unknown')\n",
                "    vo_hi_rows.append(row)\n",
                "\n",
                "vo_hi_df = pd.DataFrame(vo_hi_rows)\n",
                "vo_hi_output_file = os.path.join(DATA_DIR, 'vo_vs_hi_scores.csv')\n",
                "vo_hi_df.to_csv(vo_hi_output_file, index=False)\n",
                "print(f\"Saved VO/HI scores to {vo_hi_output_file}\")\n",
                "\n",
                "# We already have bastard stats, so no need to re-run later\n",
                "print(\"Bastard stats also computed.\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "f637e3c4",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "VO: 79\n",
                        "OV: 69\n",
                        "NDO: 37\n"
                    ]
                }
            ],
            "source": [
                "# In notebook 02 after running:\n",
                "print(f\"VO: {len([l for l in lang_vo_hi_scores.values() if l.get('vo_type') == 'VO'])}\")\n",
                "print(f\"OV: {len([l for l in lang_vo_hi_scores.values() if l.get('vo_type') == 'OV'])}\")\n",
                "print(f\"NDO: {len([l for l in lang_vo_hi_scores.values() if l.get('vo_type') == 'NDO'])}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e64365da",
            "metadata": {},
            "source": [
                "## 2b. Compute Sentence-Level Disorder (Optional)\n",
                "\n",
                "this cell is useful:\n",
                "* It handles saving: The new unified processing block I added computes the data (sentence_disorder_pct), but it does not save it. This cell converts that raw data into a DataFrame and saves it to sentence_disorder_percentages.csv and .pkl.\n",
                "* It formats the data: It transforms the raw nested dictionary into a flat table structure that is needed for the subsequent notebooks.\n",
                "\n",
                "Set `compute_sentence_disorder=True` to enable this analysis."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "7a27d8b3",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Sentence-level disorder DataFrame:\n",
                        "  Shape: (185, 2474)\n",
                        "\n",
                        "Sample:\n",
                        "  language_code language_name           group  left_tot_2_pair_0_lt  \\\n",
                        "0           abq         Abaza       Caucasian                    10   \n",
                        "1            ab        Abkhaz       Caucasian                   116   \n",
                        "2            af     Afrikaans   Indo-European                   720   \n",
                        "3           aqz       Akuntsu  South-American                     2   \n",
                        "4            sq      Albanian   Indo-European                    13   \n",
                        "\n",
                        "   left_tot_2_pair_0_eq  left_tot_2_pair_0_gt  left_tot_2_pair_0_total  \\\n",
                        "0                    19                    19                       48   \n",
                        "1                   351                   275                      742   \n",
                        "2                   323                   319                     1362   \n",
                        "3                    44                     6                       52   \n",
                        "4                    59                    41                      113   \n",
                        "\n",
                        "   left_tot_2_pair_0_lt_pct  left_tot_2_pair_0_eq_pct  \\\n",
                        "0                 20.833333                 39.583333   \n",
                        "1                 15.633423                 47.304582   \n",
                        "2                 52.863436                 23.715125   \n",
                        "3                  3.846154                 84.615385   \n",
                        "4                 11.504425                 52.212389   \n",
                        "\n",
                        "   left_tot_2_pair_0_gt_pct  ...  right_tot_18_pair_15_lt_pct  \\\n",
                        "0                 39.583333  ...                          NaN   \n",
                        "1                 37.061995  ...                          NaN   \n",
                        "2                 23.421439  ...                          NaN   \n",
                        "3                 11.538462  ...                          NaN   \n",
                        "4                 36.283186  ...                          NaN   \n",
                        "\n",
                        "   right_tot_18_pair_15_eq_pct  right_tot_18_pair_15_gt_pct  \\\n",
                        "0                          NaN                          NaN   \n",
                        "1                          NaN                          NaN   \n",
                        "2                          NaN                          NaN   \n",
                        "3                          NaN                          NaN   \n",
                        "4                          NaN                          NaN   \n",
                        "\n",
                        "   right_tot_18_pair_16_lt  right_tot_18_pair_16_eq  right_tot_18_pair_16_gt  \\\n",
                        "0                      NaN                      NaN                      NaN   \n",
                        "1                      NaN                      NaN                      NaN   \n",
                        "2                      NaN                      NaN                      NaN   \n",
                        "3                      NaN                      NaN                      NaN   \n",
                        "4                      NaN                      NaN                      NaN   \n",
                        "\n",
                        "   right_tot_18_pair_16_total  right_tot_18_pair_16_lt_pct  \\\n",
                        "0                         NaN                          NaN   \n",
                        "1                         NaN                          NaN   \n",
                        "2                         NaN                          NaN   \n",
                        "3                         NaN                          NaN   \n",
                        "4                         NaN                          NaN   \n",
                        "\n",
                        "   right_tot_18_pair_16_eq_pct  right_tot_18_pair_16_gt_pct  \n",
                        "0                          NaN                          NaN  \n",
                        "1                          NaN                          NaN  \n",
                        "2                          NaN                          NaN  \n",
                        "3                          NaN                          NaN  \n",
                        "4                          NaN                          NaN  \n",
                        "\n",
                        "[5 rows x 2474 columns]\n",
                        "\n",
                        "Saved sentence disorder data to data/\n"
                    ]
                }
            ],
            "source": [
                "# Convert sentence disorder percentages to DataFrame and save\n",
                "if sentence_disorder_pct is not None:\n",
                "    import pickle\n",
                "    \n",
                "    # Convert to DataFrame format suitable for notebook 04\n",
                "    sentence_disorder_rows = []\n",
                "    for lang_code in sentence_disorder_pct:\n",
                "        lang_name = langNames.get(lang_code, lang_code)\n",
                "        group = langnameGroup.get(lang_name, 'Unknown')\n",
                "        \n",
                "        row = {\n",
                "            'language_code': lang_code,\n",
                "            'language_name': lang_name,\n",
                "            'group': group\n",
                "        }\n",
                "        \n",
                "        # Add columns for each configuration\n",
                "        # Process granular ordering stats\n",
                "        # Key is now (side, tot, pair_idx)\n",
                "        for (side, tot, idx), counts in sentence_disorder_pct[lang_code].items():\n",
                "            total = counts['lt'] + counts['eq'] + counts['gt']\n",
                "            \n",
                "            prefix = f'{side}_tot_{tot}_pair_{idx}'\n",
                "            row[f'{prefix}_lt'] = counts['lt']\n",
                "            row[f'{prefix}_eq'] = counts['eq']\n",
                "            row[f'{prefix}_gt'] = counts['gt']\n",
                "            row[f'{prefix}_total'] = total\n",
                "            \n",
                "            if total > 0:\n",
                "                row[f'{prefix}_lt_pct'] = counts['lt'] / total * 100\n",
                "                row[f'{prefix}_eq_pct'] = counts['eq'] / total * 100\n",
                "                row[f'{prefix}_gt_pct'] = counts['gt'] / total * 100\n",
                "            else:\n",
                "                row[f'{prefix}_lt_pct'] = 0\n",
                "                row[f'{prefix}_eq_pct'] = 0\n",
                "                row[f'{prefix}_gt_pct'] = 0\n",
                "        \n",
                "        sentence_disorder_rows.append(row)\n",
                "    \n",
                "    sentence_disorder_df = pd.DataFrame(sentence_disorder_rows)\n",
                "    \n",
                "    print(f\"\\nSentence-level disorder DataFrame:\")\n",
                "    print(f\"  Shape: {sentence_disorder_df.shape}\")\n",
                "    # print(f\"  Columns: {list(sentence_disorder_df.columns)}\")\n",
                "    print(\"\\nSample:\")\n",
                "    print(sentence_disorder_df.head())\n",
                "    \n",
                "    # Save to pickle and CSV\n",
                "    with open(os.path.join(DATA_DIR, 'sentence_disorder_percentages.pkl'), 'wb') as f:\n",
                "        pickle.dump(sentence_disorder_pct, f)\n",
                "    \n",
                "    sentence_disorder_df.to_csv(os.path.join(DATA_DIR, 'sentence_disorder_percentages.csv'), index=False)\n",
                "    \n",
                "    print(f\"\\nSaved sentence disorder data to {DATA_DIR}/\")\n",
                "else:\n",
                "    print(\"Sentence-level disorder not computed (compute_sentence_disorder=False)\")\n",
                "    sentence_disorder_df = None"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5f9d5124",
            "metadata": {},
            "source": [
                "## 3. Filter by Minimum Count\n",
                "\n",
                "Remove positions that occur fewer than MIN_COUNT times to reduce noise."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "84a05136",
            "metadata": {},
            "source": [
                "## 4. Compute Mean Aggregate Length (MAL)\n",
                "\n",
                "For each language, compute MALₙ for n=1 to max available right dependents.\n",
                "\n",
                "### MAL Formula\n",
                "\n",
                "$$\n",
                "\\text{MAL}_n = \\frac{\\sum_{i=1}^{n} \\text{position2sizes}[\\text{right}\\_i\\text{\\_totright}\\_n]}{\\sum_{i=1}^{n} \\text{position2num}[\\text{right}\\_i\\text{\\_totright}\\_n]}\n",
                "$$"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "6c61136d",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Filtered to positions with at least 10 occurrences\n",
                        "Positions before filtering: 11984\n",
                        "Positions after filtering (>= 10): 6602\n",
                        "Removed: 5382 (44.9%)\n"
                    ]
                }
            ],
            "source": [
                "# Filter positions\n",
                "filtered_position2num, filtered_position2sizes = analysis.filter_by_min_count(\n",
                "    all_langs_position2num,\n",
                "    all_langs_position2sizes,\n",
                "    min_count=MIN_COUNT\n",
                ")\n",
                "\n",
                "# Count total positions before and after filtering\n",
                "total_before = sum(len(positions) for positions in all_langs_position2num.values())\n",
                "total_after = sum(len(positions) for positions in filtered_position2num.values())\n",
                "print(f\"Positions before filtering: {total_before}\")\n",
                "print(f\"Positions after filtering (>= {MIN_COUNT}): {total_after}\")\n",
                "print(f\"Removed: {total_before - total_after} ({100*(total_before - total_after)/total_before:.1f}%)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "83efac16",
            "metadata": {},
            "source": [
                "## 5. Data Structure Documentation\n",
                "\n",
                "### all_langs_position2num\n",
                "Dictionary mapping each language code to a dictionary of position keys → occurrence counts.\n",
                "\n",
                "**Structure**: `{lang_code: {position_key: count}}`\n",
                "\n",
                "**Position keys**:\n",
                "- `left_N`: N-th dependent to the left of verb (N=1 is closest)\n",
                "- `right_N`: N-th dependent to the right of verb (N=1 is closest)\n",
                "- `left_N_totleft_M`: N-th left dependent when there are M total left dependents\n",
                "- `right_N_totright_M`: N-th right dependent when there are M total right dependents\n",
                "- `average_totleft_M`: average size across all left dependents when M total\n",
                "- `average_totright_M`: average size across all right dependents when M total\n",
                "\n",
                "**Example**:\n",
                "```python\n",
                "all_langs_position2num['en'] = {\n",
                "    'left_1': 12543,\n",
                "    'right_1': 18732,\n",
                "    'right_1_totright_2': 5234,\n",
                "    ...\n",
                "}\n",
                "```\n",
                "\n",
                "### all_langs_position2sizes\n",
                "Dictionary mapping each language code to a dictionary of position keys → total size (sum of all dependency sizes).\n",
                "\n",
                "**Structure**: `{lang_code: {position_key: total_size}}`\n",
                "\n",
                "**Example**:\n",
                "```python\n",
                "all_langs_position2sizes['en'] = {\n",
                "    'left_1': 25086,  # Total size = 12543 occurrences * ~2 words average\n",
                "    'right_1': 56196,  # Total size = 18732 occurrences * ~3 words average\n",
                "    ...\n",
                "}\n",
                "```\n",
                "\n",
                "### all_langs_average_sizes\n",
                "Dictionary mapping each language code to a dictionary of position keys → average dependency size.\n",
                "\n",
                "**Structure**: `{lang_code: {position_key: average_size}}`\n",
                "\n",
                "**Computation**: `average_size = total_size / count`\n",
                "\n",
                "**Example**:\n",
                "```python\n",
                "all_langs_average_sizes['en'] = {\n",
                "    'left_1': 2.0,  # 25086 / 12543\n",
                "    'right_1': 3.0,  # 56196 / 18732\n",
                "    ...\n",
                "}\n",
                "```\n",
                "\n",
                "### lang2MAL\n",
                "Dictionary mapping each language code to a dictionary of n → MALₙ values.\n",
                "\n",
                "**Structure**: `{lang_code: {n: MAL_n}}`\n",
                "\n",
                "**Computation**: For each n, compute the mean aggregate length of right dependents from position 1 to n.\n",
                "\n",
                "**Formula**:\n",
                "$$\n",
                "\\text{MAL}_n = \\frac{\\sum_{i=1}^{n} \\text{position2sizes}[\\text{right}\\_i\\text{\\_totright}\\_n]}{\\sum_{i=1}^{n} \\text{position2num}[\\text{right}\\_i\\text{\\_totright}\\_n]}\n",
                "$$\n",
                "\n",
                "**Example**:\n",
                "```python\n",
                "lang2MAL['en'] = {\n",
                "    1: 2.5,  # Average size when 1 right dependent\n",
                "    2: 3.2,  # Average aggregate size when 2 right dependents\n",
                "    3: 3.8,  # Average aggregate size when 3 right dependents\n",
                "    ...\n",
                "}\n",
                "```\n",
                "\n",
                "**Interpretation**: MALₙ typically increases with n, indicating that having more dependents correlates with longer dependencies."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "7903261a",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "MAL computed for 185 languages\n",
                        "\n",
                        "Sample (language 'abq'):\n",
                        "{1: 1.7714285714285714}\n"
                    ]
                }
            ],
            "source": [
                "# Compute MAL for each language\n",
                "lang2MAL = analysis.compute_MAL_per_language(\n",
                "    filtered_position2sizes,\n",
                "    filtered_position2num\n",
                ")\n",
                "\n",
                "print(f\"MAL computed for {len(lang2MAL)} languages\")\n",
                "\n",
                "# Show sample\n",
                "sample_lang = list(lang2MAL.keys())[0]\n",
                "print(f\"\\nSample (language '{sample_lang}'):\")\n",
                "print(lang2MAL[sample_lang])"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0e648760",
            "metadata": {},
            "source": [
                "## Analysis of bastard frequency"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "201b5a1b",
            "metadata": {},
            "outputs": [],
            "source": [
                "# (Bastard analysis integrated into main pass)\n",
                "pass"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "25b20326",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Top 20 Languages by Bastard Frequency (per Verb):\n",
                        "   Code           Language   Verbs  Bastards  Bastards_per_Verb_Pct  \\\n",
                        "0   grc       AncientGreek   80843     24326              30.090422   \n",
                        "1   xpg           Phrygian     234        58              24.786325   \n",
                        "2    la              Latin  149655     29636              19.802880   \n",
                        "3    ps             Pashto     327        63              19.266055   \n",
                        "4   pro       OldProvençal    5468       895              16.367959   \n",
                        "5   orv      OldEastSlavic   69895     11071              15.839473   \n",
                        "6    sa           Sanskrit   40150      6230              15.516812   \n",
                        "7    hu          Hungarian    3663       491              13.404313   \n",
                        "8   swl        SwedishSign     611        81              13.256956   \n",
                        "9   fro          OldFrench   37730      4609              12.215743   \n",
                        "10  gub          Guajajára    1060       129              12.169811   \n",
                        "11  hit            Hittite     213        25              11.737089   \n",
                        "12   nl              Dutch   47886      5387              11.249635   \n",
                        "13  got             Gothic   12755      1432              11.226970   \n",
                        "14  gsw        SwissGerman    1924       215              11.174636   \n",
                        "15   sl          Slovenian   34630      3807              10.993358   \n",
                        "16   ur               Urdu   12695      1340              10.555337   \n",
                        "17   cu  OldChurchSlavonic   41405      4295              10.373143   \n",
                        "18  nds           LowSaxon    2570       259              10.077821   \n",
                        "19  frm       MiddleFrench   12492      1207               9.662184   \n",
                        "\n",
                        "    Top_Bastard_Rel  \n",
                        "0       nmod (4353)  \n",
                        "1         conj (18)  \n",
                        "2        acl (3835)  \n",
                        "3          acl (25)  \n",
                        "4         obj (160)  \n",
                        "5       conj (2085)  \n",
                        "6        acl (1816)  \n",
                        "7         obl (119)  \n",
                        "8         conj (47)  \n",
                        "9         acl (954)  \n",
                        "10  discourse (102)  \n",
                        "11         conj (5)  \n",
                        "12       acl (1002)  \n",
                        "13        obl (254)  \n",
                        "14         acl (52)  \n",
                        "15        obl (474)  \n",
                        "16        acl (428)  \n",
                        "17        acl (440)  \n",
                        "18        case (54)  \n",
                        "19       conj (246)  \n",
                        "\n",
                        "Global Bastard Relation Frequencies:\n",
                        "acl: 27396\n",
                        "conj: 21929\n",
                        "obl: 20282\n",
                        "obj: 19591\n",
                        "nmod: 18216\n",
                        "advcl: 10957\n",
                        "mark: 10643\n",
                        "advmod: 10638\n",
                        "det: 9313\n",
                        "cc: 9259\n",
                        "nsubj: 8714\n",
                        "amod: 6530\n",
                        "appos: 5901\n",
                        "case: 5834\n",
                        "expl: 5005\n",
                        "ccomp: 4765\n",
                        "xcomp: 3310\n",
                        "parataxis: 1969\n",
                        "cop: 1809\n",
                        "iobj: 1607\n",
                        "\n",
                        "Exporting examples to data/examples...\n",
                        "Exported example files for 166 languages.\n"
                    ]
                }
            ],
            "source": [
                "# Compute bastard statistics\n",
                "# Stats already computed above. Skipping re-computation.\n",
                "# lang_bastard_stats, global_bastard_relations = ...\n",
                "\n",
                "# Create a DataFrame for ranking\n",
                "ranking_data = []\n",
                "for lang, stats in lang_bastard_stats.items():\n",
                "    verbs = stats['verbs']\n",
                "    bastards = stats['bastards']\n",
                "    percentage = (bastards / verbs * 100) if verbs > 0 else 0\n",
                "    \n",
                "    # Find most frequent relation\n",
                "    relations = stats.get('relations', {})\n",
                "    if relations:\n",
                "        top_rel = max(relations, key=relations.get)\n",
                "        top_rel_count = relations[top_rel]\n",
                "        top_rel_str = f\"{top_rel} ({top_rel_count})\"\n",
                "    else:\n",
                "        top_rel_str = \"None\"\n",
                "\n",
                "    ranking_data.append({\n",
                "        'Code': lang,\n",
                "        'Language': langNames.get(lang, lang),\n",
                "        'Verbs': verbs,\n",
                "        'Bastards': bastards,\n",
                "        'Bastards_per_Verb_Pct': percentage,\n",
                "        'Top_Bastard_Rel': top_rel_str\n",
                "    })\n",
                "\n",
                "df_ranking = pd.DataFrame(ranking_data)\n",
                "df_ranking = df_ranking.sort_values('Bastards_per_Verb_Pct', ascending=False).reset_index(drop=True)\n",
                "\n",
                "print(\"\\nTop 20 Languages by Bastard Frequency (per Verb):\")\n",
                "print(df_ranking.head(20))\n",
                "\n",
                "print(\"\\nGlobal Bastard Relation Frequencies:\")\n",
                "sorted_relations = sorted(global_bastard_relations.items(), key=lambda x: x[1], reverse=True)\n",
                "for rel, count in sorted_relations[:20]:\n",
                "    print(f\"{rel}: {count}\")\n",
                "\n",
                "# Export examples\n",
                "examples_dir = os.path.join(DATA_DIR, 'examples')\n",
                "os.makedirs(examples_dir, exist_ok=True)\n",
                "\n",
                "print(f\"\\nExporting examples to {examples_dir}...\")\n",
                "count_exported = 0\n",
                "\n",
                "for lang, stats in lang_bastard_stats.items():\n",
                "    relations = stats.get('relations', {})\n",
                "    examples = stats.get('examples', {})\n",
                "    \n",
                "    if relations and examples:\n",
                "        # Get most frequent relation\n",
                "        top_rel = max(relations, key=relations.get)\n",
                "        \n",
                "        if top_rel in examples:\n",
                "            # Create file content\n",
                "            content = f\"# Language: {lang} ({langNames.get(lang, lang)})\\n\"\n",
                "            content += f\"# Most frequent bastard relation: {top_rel}\\n\"\n",
                "            content += f\"# Total bastards with this relation: {relations[top_rel]}\\n\\n\"\n",
                "            \n",
                "            for i, tree_str in enumerate(examples[top_rel]):\n",
                "                content += f\"# Example {i+1}\\n\"\n",
                "                content += tree_str + \"\\n\"\n",
                "            \n",
                "            # Save to file\n",
                "            filename = os.path.join(examples_dir, f\"{lang}_{top_rel}_examples.conllu\")\n",
                "            with open(filename, 'w', encoding='utf-8') as f:\n",
                "                f.write(content)\n",
                "            count_exported += 1\n",
                "\n",
                "print(f\"Exported example files for {count_exported} languages.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "f0ff9347",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Top Languages by Bastard Frequency (per Verb):\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Code</th>\n",
                            "      <th>Language</th>\n",
                            "      <th>Verbs</th>\n",
                            "      <th>Bastards</th>\n",
                            "      <th>Bastards_per_Verb_Pct</th>\n",
                            "      <th>Top_Bastard_Rel</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>grc</td>\n",
                            "      <td>AncientGreek</td>\n",
                            "      <td>80843</td>\n",
                            "      <td>24326</td>\n",
                            "      <td>30.090422</td>\n",
                            "      <td>nmod (4353)</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>xpg</td>\n",
                            "      <td>Phrygian</td>\n",
                            "      <td>234</td>\n",
                            "      <td>58</td>\n",
                            "      <td>24.786325</td>\n",
                            "      <td>conj (18)</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>la</td>\n",
                            "      <td>Latin</td>\n",
                            "      <td>149655</td>\n",
                            "      <td>29636</td>\n",
                            "      <td>19.802880</td>\n",
                            "      <td>acl (3835)</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>ps</td>\n",
                            "      <td>Pashto</td>\n",
                            "      <td>327</td>\n",
                            "      <td>63</td>\n",
                            "      <td>19.266055</td>\n",
                            "      <td>acl (25)</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>pro</td>\n",
                            "      <td>OldProvençal</td>\n",
                            "      <td>5468</td>\n",
                            "      <td>895</td>\n",
                            "      <td>16.367959</td>\n",
                            "      <td>obj (160)</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>180</th>\n",
                            "      <td>bor</td>\n",
                            "      <td>Borôro</td>\n",
                            "      <td>27057</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>None</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>181</th>\n",
                            "      <td>az</td>\n",
                            "      <td>Azerbaijani</td>\n",
                            "      <td>190</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>None</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>182</th>\n",
                            "      <td>aii</td>\n",
                            "      <td>Assyrian</td>\n",
                            "      <td>57</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>None</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>183</th>\n",
                            "      <td>apu</td>\n",
                            "      <td>Apurinã</td>\n",
                            "      <td>215</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>None</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>184</th>\n",
                            "      <td>vep</td>\n",
                            "      <td>Veps</td>\n",
                            "      <td>183</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>None</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>185 rows × 6 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "    Code      Language   Verbs  Bastards  Bastards_per_Verb_Pct  \\\n",
                            "0    grc  AncientGreek   80843     24326              30.090422   \n",
                            "1    xpg      Phrygian     234        58              24.786325   \n",
                            "2     la         Latin  149655     29636              19.802880   \n",
                            "3     ps        Pashto     327        63              19.266055   \n",
                            "4    pro  OldProvençal    5468       895              16.367959   \n",
                            "..   ...           ...     ...       ...                    ...   \n",
                            "180  bor        Borôro   27057         0               0.000000   \n",
                            "181   az   Azerbaijani     190         0               0.000000   \n",
                            "182  aii      Assyrian      57         0               0.000000   \n",
                            "183  apu       Apurinã     215         0               0.000000   \n",
                            "184  vep          Veps     183         0               0.000000   \n",
                            "\n",
                            "    Top_Bastard_Rel  \n",
                            "0       nmod (4353)  \n",
                            "1         conj (18)  \n",
                            "2        acl (3835)  \n",
                            "3          acl (25)  \n",
                            "4         obj (160)  \n",
                            "..              ...  \n",
                            "180            None  \n",
                            "181            None  \n",
                            "182            None  \n",
                            "183            None  \n",
                            "184            None  \n",
                            "\n",
                            "[185 rows x 6 columns]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Global Bastard Relation Frequencies:\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Relation</th>\n",
                            "      <th>Count</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>acl</td>\n",
                            "      <td>27396</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>conj</td>\n",
                            "      <td>21929</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>obl</td>\n",
                            "      <td>20282</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>obj</td>\n",
                            "      <td>19591</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>nmod</td>\n",
                            "      <td>18216</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>5</th>\n",
                            "      <td>advcl</td>\n",
                            "      <td>10957</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>6</th>\n",
                            "      <td>mark</td>\n",
                            "      <td>10643</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>7</th>\n",
                            "      <td>advmod</td>\n",
                            "      <td>10638</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>8</th>\n",
                            "      <td>det</td>\n",
                            "      <td>9313</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>9</th>\n",
                            "      <td>cc</td>\n",
                            "      <td>9259</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>10</th>\n",
                            "      <td>nsubj</td>\n",
                            "      <td>8714</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>11</th>\n",
                            "      <td>amod</td>\n",
                            "      <td>6530</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>12</th>\n",
                            "      <td>appos</td>\n",
                            "      <td>5901</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>13</th>\n",
                            "      <td>case</td>\n",
                            "      <td>5834</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>14</th>\n",
                            "      <td>expl</td>\n",
                            "      <td>5005</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>15</th>\n",
                            "      <td>ccomp</td>\n",
                            "      <td>4765</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>16</th>\n",
                            "      <td>xcomp</td>\n",
                            "      <td>3310</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>17</th>\n",
                            "      <td>parataxis</td>\n",
                            "      <td>1969</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>18</th>\n",
                            "      <td>cop</td>\n",
                            "      <td>1809</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>19</th>\n",
                            "      <td>iobj</td>\n",
                            "      <td>1607</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>20</th>\n",
                            "      <td>dislocated</td>\n",
                            "      <td>1131</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>21</th>\n",
                            "      <td>nummod</td>\n",
                            "      <td>1105</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>22</th>\n",
                            "      <td>discourse</td>\n",
                            "      <td>951</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>23</th>\n",
                            "      <td>aux</td>\n",
                            "      <td>803</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>24</th>\n",
                            "      <td>dep</td>\n",
                            "      <td>558</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>25</th>\n",
                            "      <td>csubj</td>\n",
                            "      <td>510</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>26</th>\n",
                            "      <td>reparandum</td>\n",
                            "      <td>487</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>27</th>\n",
                            "      <td>orphan</td>\n",
                            "      <td>363</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>28</th>\n",
                            "      <td>vocative</td>\n",
                            "      <td>338</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>29</th>\n",
                            "      <td>compound</td>\n",
                            "      <td>281</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>30</th>\n",
                            "      <td>flat</td>\n",
                            "      <td>275</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>31</th>\n",
                            "      <td>fixed</td>\n",
                            "      <td>153</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>32</th>\n",
                            "      <td>list</td>\n",
                            "      <td>41</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>33</th>\n",
                            "      <td>clf</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "      Relation  Count\n",
                            "0          acl  27396\n",
                            "1         conj  21929\n",
                            "2          obl  20282\n",
                            "3          obj  19591\n",
                            "4         nmod  18216\n",
                            "5        advcl  10957\n",
                            "6         mark  10643\n",
                            "7       advmod  10638\n",
                            "8          det   9313\n",
                            "9           cc   9259\n",
                            "10       nsubj   8714\n",
                            "11        amod   6530\n",
                            "12       appos   5901\n",
                            "13        case   5834\n",
                            "14        expl   5005\n",
                            "15       ccomp   4765\n",
                            "16       xcomp   3310\n",
                            "17   parataxis   1969\n",
                            "18         cop   1809\n",
                            "19        iobj   1607\n",
                            "20  dislocated   1131\n",
                            "21      nummod   1105\n",
                            "22   discourse    951\n",
                            "23         aux    803\n",
                            "24         dep    558\n",
                            "25       csubj    510\n",
                            "26  reparandum    487\n",
                            "27      orphan    363\n",
                            "28    vocative    338\n",
                            "29    compound    281\n",
                            "30        flat    275\n",
                            "31       fixed    153\n",
                            "32        list     41\n",
                            "33         clf      1"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# showing the bastard tables as df\n",
                "\n",
                "pd.set_option('display.max_rows', 50)\n",
                "\n",
                "print(\"Top Languages by Bastard Frequency (per Verb):\")\n",
                "display(df_ranking)\n",
                "\n",
                "print(\"\\nGlobal Bastard Relation Frequencies:\")\n",
                "df_global_relations = pd.DataFrame(\n",
                "    sorted(global_bastard_relations.items(), key=lambda x: x[1], reverse=True),\n",
                "    columns=['Relation', 'Count']\n",
                ")\n",
                "display(df_global_relations)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e950f09b",
            "metadata": {},
            "source": [
                "## 6. Export Analysis Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "9ea258a6",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Saved all_langs_position2num.pkl\n",
                        "Saved all_langs_position2sizes.pkl\n",
                        "Saved all_langs_average_sizes.pkl\n",
                        "Saved filtered_position2num.pkl\n",
                        "Saved filtered_position2sizes.pkl\n",
                        "Saved lang2MAL.pkl\n",
                        "All analysis results saved to data/\n",
                        "Analysis results saved to data/\n"
                    ]
                }
            ],
            "source": [
                "# Save all analysis results\n",
                "analysis.save_analysis_results(\n",
                "    all_langs_position2num,\n",
                "    all_langs_position2sizes,\n",
                "    all_langs_average_sizes,\n",
                "    filtered_position2num,\n",
                "    filtered_position2sizes,\n",
                "    lang2MAL,\n",
                "    output_dir=DATA_DIR\n",
                ")\n",
                "\n",
                "print(f\"Analysis results saved to {DATA_DIR}/\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f214f92e",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "This notebook has:\n",
                "- ✅ Loaded metadata from notebook 01\n",
                "- ✅ Processed all CoNLL files in parallel (extracted dependency sizes)\n",
                "- ✅ Filtered positions by minimum count (>= 10)\n",
                "- ✅ Computed Mean Aggregate Length (MAL) for each language\n",
                "- ✅ Exported 6 analysis result files to data/\n",
                "- ✅ Analyzed bastard frequencies and exported examples\n",
                "\n",
                "**Next step**: Run `03_visualization.ipynb` to create plots and explore results."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f6a98a7c",
            "metadata": {},
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "ragenv",
            "language": "python",
            "name": "ragenv"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
