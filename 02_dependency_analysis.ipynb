{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97dabcb5",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f1f0fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import custom modules\n",
    "import data_utils\n",
    "import conll_processing\n",
    "import analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b66220a",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b63a2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data\"\n",
    "MIN_COUNT = 10  # Minimum occurrence count for positions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d125414d",
   "metadata": {},
   "source": [
    "## 1. Load Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54ea090a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded metadata from data/metadata.pkl\n",
      "UD version: 2.17\n",
      "Languages: 186\n",
      "Total short files to process: 814\n"
     ]
    }
   ],
   "source": [
    "# Load metadata from notebook 01\n",
    "metadata = data_utils.load_metadata(os.path.join(DATA_DIR, 'metadata.pkl'))\n",
    "\n",
    "langShortConllFiles = metadata['langShortConllFiles']\n",
    "langNames = metadata['langNames']\n",
    "langnameGroup = metadata['langnameGroup']\n",
    "appearance_dict = metadata['appearance_dict']\n",
    "ud_version = metadata['ud_version']\n",
    "\n",
    "print(f\"UD version: {ud_version}\")\n",
    "print(f\"Languages: {len(langShortConllFiles)}\")\n",
    "total_files = sum(len(files) for files in langShortConllFiles.values())\n",
    "print(f\"Total short files to process: {total_files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70be9a3",
   "metadata": {},
   "source": [
    "## 2. Process CoNLL Files in Parallel\n",
    "\n",
    "This step extracts dependency sizes for all verbal constructions across all languages.\n",
    "It uses multiprocessing to parallelize across CPU cores.\n",
    "\n",
    "**Note**: This is the most computationally intensive step and may take a long time depending on your system. On Calcul, this takes less than 40 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cc815da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 814 files in parallel...\n"
     ]
    }
   ],
   "source": [
    "# Flatten all short files into a single list\n",
    "allshortconll = []\n",
    "for lang, files in langShortConllFiles.items():\n",
    "    allshortconll.extend(files)\n",
    "\n",
    "print(f\"Processing {len(allshortconll)} files in parallel...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bef6076e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing all files, running on 80 cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 814/814 [00:34<00:00, 23.56it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing. Combining results...\n",
      "Done!\n",
      "Processing complete!\n",
      "Results computed for 186 languages\n",
      "Done!\n",
      "Processing complete!\n",
      "Results computed for 186 languages\n"
     ]
    }
   ],
   "source": [
    "# Process files in parallel\n",
    "all_langs_position2num, all_langs_position2sizes, all_langs_average_sizes = conll_processing.get_type_freq_all_files_parallel(allshortconll)\n",
    "print(\"Processing complete!\")\n",
    "print(f\"Results computed for {len(all_langs_position2num)} languages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d5124",
   "metadata": {},
   "source": [
    "## 3. Filter by Minimum Count\n",
    "\n",
    "Remove positions that occur fewer than MIN_COUNT times to reduce noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a05136",
   "metadata": {},
   "source": [
    "## 4. Compute Mean Aggregate Length (MAL)\n",
    "\n",
    "For each language, compute MALₙ for n=1 to max available right dependents.\n",
    "\n",
    "### MAL Formula\n",
    "\n",
    "$$\n",
    "\\text{MAL}_n = \\frac{\\sum_{i=1}^{n} \\text{position2sizes}[\\text{right}\\_i\\text{\\_totright}\\_n]}{\\sum_{i=1}^{n} \\text{position2num}[\\text{right}\\_i\\text{\\_totright}\\_n]}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c61136d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered to positions with at least 10 occurrences\n",
      "Positions before filtering: 10759\n",
      "Positions after filtering (>= 10): 6372\n",
      "Removed: 4387 (40.8%)\n"
     ]
    }
   ],
   "source": [
    "# Filter positions\n",
    "filtered_position2num, filtered_position2sizes = analysis.filter_by_min_count(\n",
    "    all_langs_position2num,\n",
    "    all_langs_position2sizes,\n",
    "    min_count=MIN_COUNT\n",
    ")\n",
    "\n",
    "# Count total positions before and after filtering\n",
    "total_before = sum(len(positions) for positions in all_langs_position2num.values())\n",
    "total_after = sum(len(positions) for positions in filtered_position2num.values())\n",
    "print(f\"Positions before filtering: {total_before}\")\n",
    "print(f\"Positions after filtering (>= {MIN_COUNT}): {total_after}\")\n",
    "print(f\"Removed: {total_before - total_after} ({100*(total_before - total_after)/total_before:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83efac16",
   "metadata": {},
   "source": [
    "## 5. Data Structure Documentation\n",
    "\n",
    "### all_langs_position2num\n",
    "Dictionary mapping each language code to a dictionary of position keys → occurrence counts.\n",
    "\n",
    "**Structure**: `{lang_code: {position_key: count}}`\n",
    "\n",
    "**Position keys**:\n",
    "- `left_N`: N-th dependent to the left of verb (N=1 is closest)\n",
    "- `right_N`: N-th dependent to the right of verb (N=1 is closest)\n",
    "- `left_N_totleft_M`: N-th left dependent when there are M total left dependents\n",
    "- `right_N_totright_M`: N-th right dependent when there are M total right dependents\n",
    "- `average_totleft_M`: average size across all left dependents when M total\n",
    "- `average_totright_M`: average size across all right dependents when M total\n",
    "\n",
    "**Example**:\n",
    "```python\n",
    "all_langs_position2num['en'] = {\n",
    "    'left_1': 12543,\n",
    "    'right_1': 18732,\n",
    "    'right_1_totright_2': 5234,\n",
    "    ...\n",
    "}\n",
    "```\n",
    "\n",
    "### all_langs_position2sizes\n",
    "Dictionary mapping each language code to a dictionary of position keys → total size (sum of all dependency sizes).\n",
    "\n",
    "**Structure**: `{lang_code: {position_key: total_size}}`\n",
    "\n",
    "**Example**:\n",
    "```python\n",
    "all_langs_position2sizes['en'] = {\n",
    "    'left_1': 25086,  # Total size = 12543 occurrences * ~2 words average\n",
    "    'right_1': 56196,  # Total size = 18732 occurrences * ~3 words average\n",
    "    ...\n",
    "}\n",
    "```\n",
    "\n",
    "### all_langs_average_sizes\n",
    "Dictionary mapping each language code to a dictionary of position keys → average dependency size.\n",
    "\n",
    "**Structure**: `{lang_code: {position_key: average_size}}`\n",
    "\n",
    "**Computation**: `average_size = total_size / count`\n",
    "\n",
    "**Example**:\n",
    "```python\n",
    "all_langs_average_sizes['en'] = {\n",
    "    'left_1': 2.0,  # 25086 / 12543\n",
    "    'right_1': 3.0,  # 56196 / 18732\n",
    "    ...\n",
    "}\n",
    "```\n",
    "\n",
    "### lang2MAL\n",
    "Dictionary mapping each language code to a dictionary of n → MALₙ values.\n",
    "\n",
    "**Structure**: `{lang_code: {n: MAL_n}}`\n",
    "\n",
    "**Computation**: For each n, compute the mean aggregate length of right dependents from position 1 to n.\n",
    "\n",
    "**Formula**:\n",
    "$$\n",
    "\\text{MAL}_n = \\frac{\\sum_{i=1}^{n} \\text{position2sizes}[\\text{right}\\_i\\text{\\_totright}\\_n]}{\\sum_{i=1}^{n} \\text{position2num}[\\text{right}\\_i\\text{\\_totright}\\_n]}\n",
    "$$\n",
    "\n",
    "**Example**:\n",
    "```python\n",
    "lang2MAL['en'] = {\n",
    "    1: 2.5,  # Average size when 1 right dependent\n",
    "    2: 3.2,  # Average aggregate size when 2 right dependents\n",
    "    3: 3.8,  # Average aggregate size when 3 right dependents\n",
    "    ...\n",
    "}\n",
    "```\n",
    "\n",
    "**Interpretation**: MALₙ typically increases with n, indicating that having more dependents correlates with longer dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7903261a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAL computed for 186 languages\n",
      "\n",
      "Sample (language 'abq'):\n",
      "{1: 1.8055555555555556}\n"
     ]
    }
   ],
   "source": [
    "# Compute MAL for each language\n",
    "lang2MAL = analysis.compute_MAL_per_language(\n",
    "    filtered_position2sizes,\n",
    "    filtered_position2num\n",
    ")\n",
    "\n",
    "print(f\"MAL computed for {len(lang2MAL)} languages\")\n",
    "\n",
    "# Show sample\n",
    "sample_lang = list(lang2MAL.keys())[0]\n",
    "print(f\"\\nSample (language '{sample_lang}'):\")\n",
    "print(lang2MAL[sample_lang])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bcee53",
   "metadata": {},
   "source": [
    "## 7. Data Structure Documentation\n",
    "\n",
    "### all_langs_position2num\n",
    "Dictionary mapping each language code to a dictionary of position keys → occurrence counts.\n",
    "\n",
    "**Structure**: `{lang_code: {position_key: count}}`\n",
    "\n",
    "**Position keys**:\n",
    "- `left_N`: N-th dependent to the left of verb (N=1 is closest)\n",
    "- `right_N`: N-th dependent to the right of verb (N=1 is closest)\n",
    "- `left_N_totleft_M`: N-th left dependent when there are M total left dependents\n",
    "- `right_N_totright_M`: N-th right dependent when there are M total right dependents\n",
    "- `average_totleft_M`: average size across all left dependents when M total\n",
    "- `average_totright_M`: average size across all right dependents when M total\n",
    "\n",
    "**Example**:\n",
    "```python\n",
    "all_langs_position2num['en'] = {\n",
    "    'left_1': 12543,\n",
    "    'right_1': 18732,\n",
    "    'right_1_totright_2': 5234,\n",
    "    ...\n",
    "}\n",
    "```\n",
    "\n",
    "### all_langs_position2sizes\n",
    "Dictionary mapping each language code to a dictionary of position keys → total size (sum of all dependency sizes).\n",
    "\n",
    "**Structure**: `{lang_code: {position_key: total_size}}`\n",
    "\n",
    "**Example**:\n",
    "```python\n",
    "all_langs_position2sizes['en'] = {\n",
    "    'left_1': 25086,  # Total size = 12543 occurrences * ~2 words average\n",
    "    'right_1': 56196,  # Total size = 18732 occurrences * ~3 words average\n",
    "    ...\n",
    "}\n",
    "```\n",
    "\n",
    "### all_langs_average_sizes\n",
    "Dictionary mapping each language code to a dictionary of position keys → average dependency size.\n",
    "\n",
    "**Structure**: `{lang_code: {position_key: average_size}}`\n",
    "\n",
    "**Computation**: `average_size = total_size / count`\n",
    "\n",
    "**Example**:\n",
    "```python\n",
    "all_langs_average_sizes['en'] = {\n",
    "    'left_1': 2.0,  # 25086 / 12543\n",
    "    'right_1': 3.0,  # 56196 / 18732\n",
    "    ...\n",
    "}\n",
    "```\n",
    "\n",
    "### lang2MAL\n",
    "Dictionary mapping each language code to a dictionary of n → MALₙ values.\n",
    "\n",
    "**Structure**: `{lang_code: {n: MAL_n}}`\n",
    "\n",
    "**Computation**: For each n, compute the mean aggregate length of right dependents from position 1 to n.\n",
    "\n",
    "**Formula**:\n",
    "$$\n",
    "\\text{MAL}_n = \\frac{\\sum_{i=1}^{n} \\text{position2sizes}[\\text{right}\\_i\\text{\\_totright}\\_n]}{\\sum_{i=1}^{n} \\text{position2num}[\\text{right}\\_i\\text{\\_totright}\\_n]}\n",
    "$$\n",
    "\n",
    "**Example**:\n",
    "```python\n",
    "lang2MAL['en'] = {\n",
    "    1: 2.5,  # Average size when 1 right dependent\n",
    "    2: 3.2,  # Average aggregate size when 2 right dependents\n",
    "    3: 3.8,  # Average aggregate size when 3 right dependents\n",
    "    ...\n",
    "}\n",
    "```\n",
    "\n",
    "**Interpretation**: MALₙ typically increases with n, indicating that having more dependents correlates with longer dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e950f09b",
   "metadata": {},
   "source": [
    "## 6. Export Analysis Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ea258a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all_langs_position2num.pkl\n",
      "Saved all_langs_position2sizes.pkl\n",
      "Saved all_langs_average_sizes.pkl\n",
      "Saved filtered_position2num.pkl\n",
      "Saved filtered_position2sizes.pkl\n",
      "Saved lang2MAL.pkl\n",
      "All analysis results saved to data/\n",
      "Analysis results saved to data/\n"
     ]
    }
   ],
   "source": [
    "# Save all analysis results\n",
    "analysis.save_analysis_results(\n",
    "    all_langs_position2num,\n",
    "    all_langs_position2sizes,\n",
    "    all_langs_average_sizes,\n",
    "    filtered_position2num,\n",
    "    filtered_position2sizes,\n",
    "    lang2MAL,\n",
    "    output_dir=DATA_DIR\n",
    ")\n",
    "\n",
    "print(f\"Analysis results saved to {DATA_DIR}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f214f92e",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has:\n",
    "- ✅ Loaded metadata from notebook 01\n",
    "- ✅ Processed all CoNLL files in parallel (extracted dependency sizes)\n",
    "- ✅ Filtered positions by minimum count (>= 10)\n",
    "- ✅ Computed Mean Aggregate Length (MAL) for each language\n",
    "- ✅ Exported 6 analysis result files to data/\n",
    "\n",
    "**Next step**: Run `03_visualization.ipynb` to create plots and explore results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a98a7c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
