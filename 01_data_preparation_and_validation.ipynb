{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5b7c3c9",
   "metadata": {},
   "source": [
    "# 1. Data Preparation & Validation\n",
    "\n",
    "**Summary**: This notebook initializes the pipeline by downloading Universal Dependencies treebanks, validating language codes against Google Sheets metadata, and preparing the data for efficient parallel processing.\n",
    "\n",
    "**Key Steps**:\n",
    "1. Download and extract UD treebanks (v2.17).\n",
    "2. Load language metadata from Google Sheets.\n",
    "3. Validate ISO language codes and family groupings.\n",
    "4. Compute corpus statistics (sentence counts, token counts).\n",
    "5. **Critical**: Split large CoNLL files into 10k-sentence chunks (`*_short/*.conllu`) for parallelization.\n",
    "\n",
    "**Inputs**:\n",
    "- `ud-treebanks-v2.17/` (Raw CoNLL-U files)\n",
    "- Google Sheets Credentials (`typometrics-*.json`)\n",
    "\n",
    "**Outputs**:\n",
    "- `data/metadata.pkl` (Pipeline configuration state)\n",
    "- `2.17_short/` (Directory of processed short CoNLL files)\n",
    "- Google Sheets Updates (Validation columns)\n",
    "\n",
    "**Runtime**: ~1 minute\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ea3d0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import custom modules\n",
    "import data_utils\n",
    "import conll_processing\n",
    "import validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731e293a",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7dc29f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths and constants\n",
    "UD_VERSION = \"2.17\"\n",
    "UD_DIR = f\"ud-treebanks-v{UD_VERSION}\"\n",
    "CREDENTIALS_FILE = \"typometrics-c4750cac2e21.json\"\n",
    "SPREADSHEET_URL = \"https://docs.google.com/spreadsheets/d/1IP3ebsNNVAsQ5sxmBnfEAmZc4f0iotAL9hd4aqOOcEg/edit\"\n",
    "DATA_DIR = \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25daf473",
   "metadata": {},
   "source": [
    "## 1. Download and Extract UD Treebanks\n",
    "\n",
    "Download the latest UD treebanks from the official repository if not already present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54bef594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UD treebanks v2.17 found at: /bigstorage/kim/typometrics/dataanalysis/ud-treebanks-v2.17\n"
     ]
    }
   ],
   "source": [
    "# Check if already downloaded\n",
    "if not os.path.exists(UD_DIR):\n",
    "    print(f\"UD treebanks v{UD_VERSION} not found. Please download manually:\")\n",
    "    print(f\"https://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-5772\")\n",
    "    print(f\"Extract to: {os.path.abspath(UD_DIR)}\")\n",
    "else:\n",
    "    print(f\"UD treebanks v{UD_VERSION} found at: {os.path.abspath(UD_DIR)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612fa0cf",
   "metadata": {},
   "source": [
    "## 2. Load CoNLL Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce9858f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Languages represented: 187\n",
      "Sample languages: ['abq', 'ab', 'af', 'akk', 'aqz', 'sq', 'gsw', 'am', 'grc', 'hbo']\n"
     ]
    }
   ],
   "source": [
    "# Find all CoNLL-U files and group by language\n",
    "# This matches the original getAllConllFilesGroup() function\n",
    "langConllFiles = {}\n",
    "\n",
    "# List all directories in the UD folder\n",
    "doc_list = [d for d in sorted(os.listdir(UD_DIR)) if os.path.isdir(os.path.join(UD_DIR, d))]\n",
    "\n",
    "for doc_name in doc_list:\n",
    "    doc_path = os.path.join(UD_DIR, doc_name)\n",
    "    # Find all .conllu files in this directory (excluding not-to-release)\n",
    "    conll_files = [\n",
    "        os.path.join(doc_path, f) \n",
    "        for f in os.listdir(doc_path) \n",
    "        if f.endswith(\".conllu\") and \"not-to-release\" not in doc_name\n",
    "    ]\n",
    "    \n",
    "    if conll_files:\n",
    "        # Extract language code from first filename (e.g., en_ewt-ud-train.conllu -> en)\n",
    "        first_file = os.path.basename(conll_files[0])\n",
    "        \n",
    "        # Special handling for fr_alts (Old/Middle French mixed)\n",
    "        if first_file.startswith(\"fr_alts\"):\n",
    "            lang_code = \"fr_alts\"\n",
    "        else:\n",
    "            lang_code = first_file.split('_', 1)[0].lower()\n",
    "        \n",
    "        # Add all files for this language\n",
    "        if lang_code not in langConllFiles:\n",
    "            langConllFiles[lang_code] = []\n",
    "        langConllFiles[lang_code].extend(conll_files)\n",
    "\n",
    "print(f\"Languages represented: {len(langConllFiles)}\")\n",
    "print(f\"Sample languages: {list(langConllFiles.keys())[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee018b9f",
   "metadata": {},
   "source": [
    "## 3. Load Google Sheets Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57125120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sheets: ['my_language', 'language_to_group', 'appearance', 'all_languages_code']\n"
     ]
    }
   ],
   "source": [
    "# Load Google Sheets data\n",
    "sheets_data = data_utils.load_google_sheets(CREDENTIALS_FILE, SPREADSHEET_URL)\n",
    "print(\"Loaded sheets:\", list(sheets_data['sheets'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a597703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "my_language:\n",
      "  code        displayName\n",
      "0   ca            Catalan\n",
      "1   cu  OldChurchSlavonic\n",
      "2   nl              Dutch\n",
      "3   el              Greek\n",
      "4   ht            Haitian\n",
      "\n",
      "language_to_group:\n",
      "    Language          Group     Genus Column 1    Simple Group Area\n",
      "0      Abaza      Caucasian                          Caucasian    E\n",
      "1     Abkhaz      Caucasian                          Caucasian    E\n",
      "2  Afrikaans  Indo-European  Germanic            Indo-European   Af\n",
      "3   Akkadian        Semitic                        Afroasiatic   ME\n",
      "4    Akuntsu         Tupian                     South-American   SA\n",
      "\n",
      "appearance:\n",
      "           Group Default Color\n",
      "0         Italic         brown\n",
      "1    Baltoslavic        purple\n",
      "2       Germanic         olive\n",
      "3  Indo-European     royalBlue\n",
      "4   Austronesian     limeGreen\n",
      "\n",
      "all_languages_code:\n",
      "  code   language\n",
      "0   ab  Abkhazian\n",
      "1   aa       Afar\n",
      "2   af  Afrikaans\n",
      "3   ak       Akan\n",
      "4   sq   Albanian\n"
     ]
    }
   ],
   "source": [
    "# Display sheet previews\n",
    "for sheet_name, df in sheets_data['dataframes'].items():\n",
    "    print(f\"\\n{sheet_name}:\")\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc97250d",
   "metadata": {},
   "source": [
    "## 4. Create Language Mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "870bbf32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total language codes available: 8041\n",
      "Languages in our treebanks: 187\n",
      "Languages with names: 187\n",
      "Total language groups: 11\n",
      "Groups with colors: 29\n"
     ]
    }
   ],
   "source": [
    "# Create language mappings\n",
    "# Note: langNames comes from all_languages_code sheet (all ISO codes),\n",
    "# then overridden by my_language sheet (custom display names for languages with spaces)\n",
    "mappings = data_utils.create_language_mappings(sheets_data)\n",
    "\n",
    "# Filter to only languages in our treebanks\n",
    "all_langNames = mappings['langNames']\n",
    "langNames = {lang: all_langNames[lang] for lang in langConllFiles if lang in all_langNames}\n",
    "\n",
    "# Manually add fr_alts if not present\n",
    "if 'fr_alts' in langConllFiles and 'fr_alts' not in langNames:\n",
    "    langNames['fr_alts'] = \"French (Alternative)\"\n",
    "\n",
    "langnameGroup = mappings['langnameGroup']\n",
    "\n",
    "# Manually add group for fr_alts\n",
    "if 'French (Alternative)' not in langnameGroup:\n",
    "    langnameGroup['French (Alternative)'] = 'Indo-European'\n",
    "\n",
    "group2lang = mappings['group2lang']\n",
    "appearance_dict = mappings['appearance_dict']\n",
    "\n",
    "print(f\"Total language codes available: {len(all_langNames)}\")\n",
    "print(f\"Languages in our treebanks: {len(langConllFiles)}\")\n",
    "print(f\"Languages with names: {len(langNames)}\")\n",
    "print(f\"Total language groups: {len(set(langnameGroup.values()))}\")\n",
    "print(f\"Groups with colors: {len(appearance_dict)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa64004b",
   "metadata": {},
   "source": [
    "## 5. Validate Language Codes\n",
    "\n",
    "Check which languages in our treebanks:\n",
    "- Have names with spaces (need custom display names in my_language sheet)\n",
    "- Are missing from the language code mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e41906ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language with space:\n",
      " fr_alts: French (Alternative)\n",
      "Language to add: []\n",
      "Language code validation complete. Check Google Sheet column E for results.\n"
     ]
    }
   ],
   "source": [
    "# Validate language codes\n",
    "my_language_sheet = sheets_data['sheets']['my_language']\n",
    "validation.validate_language_codes(langConllFiles, langNames, my_language_sheet)\n",
    "print(\"Language code validation complete. Check Google Sheet column E for results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b80d467",
   "metadata": {},
   "source": [
    "## 6. Validate Language Groups\n",
    "\n",
    "Check which languages in our treebanks are missing group assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a19f838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 language groups to add:\n",
      " \n",
      "['OK', '', '', '', '', '', '', '', '', '', '']\n",
      "Language group validation complete. Check Google Sheet column H for results.\n"
     ]
    }
   ],
   "source": [
    "# Validate language groups\n",
    "language_to_group_sheet = sheets_data['sheets']['language_to_group']\n",
    "validation.validate_language_groups(langConllFiles, langNames, langnameGroup, language_to_group_sheet)\n",
    "print(\"Language group validation complete. Check Google Sheet column H for results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa00a74d",
   "metadata": {},
   "source": [
    "## 7. Compute Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db03cf47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f29daa2b153349d2950b55e89fac4bfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing statistics:   0%|          | 0/187 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   language   languageName           group  nConllFiles  nSentences  nTokens  \\\n",
      "0       abq          Abaza       Caucasian            1          98     1240   \n",
      "1        ab         Abkhaz       Caucasian            1        1316    14533   \n",
      "2        af      Afrikaans   Indo-European            3        1936    55062   \n",
      "3       akk       Akkadian     Afroasiatic            2        1976    31588   \n",
      "4       aqz        Akuntsu  South-American            1         343     2762   \n",
      "5        sq       Albanian   Indo-European            4         263     5270   \n",
      "6       gsw    SwissGerman   Indo-European            2        1078    26213   \n",
      "7        am        Amharic     Afroasiatic            1        1074    15932   \n",
      "8       grc   AncientGreek   Indo-European            9       32585   540353   \n",
      "9       hbo  AncientHebrew     Afroasiatic            3        5610   208302   \n",
      "10      apu        Apurinã  South-American            1         165     1990   \n",
      "11       ar         Arabic     Afroasiatic            7       28408  1259114   \n",
      "12       hy       Armenian   Indo-European            6        8055   179244   \n",
      "13      aii       Assyrian     Afroasiatic            1          57      568   \n",
      "14       az    Azerbaijani          Turkic            1         148     1651   \n",
      "15       bm        Bambara     Niger-Congo            1        1026    15909   \n",
      "16       eu         Basque           Other            3        8995   139431   \n",
      "17      bar       Bavarian   Indo-European            1        1070    21815   \n",
      "18      bej           Beja     Afroasiatic            1         763    16184   \n",
      "19       be     Belarusian   Indo-European            3       25233   431580   \n",
      "\n",
      "    avgSentenceLength  \n",
      "0           12.653061  \n",
      "1           11.043313  \n",
      "2           28.441116  \n",
      "3           15.985830  \n",
      "4            8.052478  \n",
      "5           20.038023  \n",
      "6           24.316327  \n",
      "7           14.834264  \n",
      "8           16.582876  \n",
      "9           37.130481  \n",
      "10          12.060606  \n",
      "11          44.322515  \n",
      "12          22.252514  \n",
      "13           9.964912  \n",
      "14          11.155405  \n",
      "15          15.505848  \n",
      "16          15.500945  \n",
      "17          20.387850  \n",
      "18          21.211009  \n",
      "19          17.103793  \n"
     ]
    }
   ],
   "source": [
    "# Compute basic statistics for each language\n",
    "stats_df = validation.compute_basic_statistics(langConllFiles, langNames, langnameGroup)\n",
    "print(stats_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc861fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      "       nConllFiles     nSentences       nTokens  avgSentenceLength\n",
      "count   187.000000     187.000000  1.870000e+02         187.000000\n",
      "mean      3.668449   12374.481283  2.462718e+05          17.454225\n",
      "std       4.462173   33503.767111  6.739618e+05           7.215887\n",
      "min       1.000000       8.000000  8.700000e+01           6.220447\n",
      "25%       1.000000     249.500000  3.466000e+03          11.990610\n",
      "50%       2.000000    1260.000000  1.864100e+04          15.680795\n",
      "75%       4.000000    5878.000000  1.430990e+05          21.986056\n",
      "max      29.000000  253797.000000  5.285270e+06          44.322515\n"
     ]
    }
   ],
   "source": [
    "# Summary statistics\n",
    "print(\"\\nSummary:\")\n",
    "print(stats_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f04927",
   "metadata": {},
   "source": [
    "## 8. Create Short CoNLL Files\n",
    "\n",
    "Split large CoNLL files into chunks of 10,000 sentences for parallel processing.\n",
    "This takes 33 seconds on Calcul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5a871ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating short CoNLL files (removes existing directory and recreates)...\n",
      "Excluding 4 treebanks: UD_Akkadian-PISANDUB, UD_Akkadian-RIAO, UD_French-ALTS, UD_French-PoitevinDIVITAL\n",
      "Removing existing directory: 2.17_short\n",
      "Created fresh directory: 2.17_short\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing languages: 100%|██████████| 187/187 [00:18<00:00, 10.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 808 short CoNLL files in 2.17_short\n",
      "Short files created: 808 files for 187 languages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create short CoNLL files\n",
    "# This function removes and recreates the directory to ensure excluded treebanks are not present\n",
    "print(\"Creating short CoNLL files (removes existing directory and recreates)...\")\n",
    "langShortConllFiles, allshortconll = conll_processing.make_shorter_conll_files(langConllFiles, UD_VERSION)\n",
    "print(f\"Short files created: {len(allshortconll)} files for {len(langShortConllFiles)} languages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a2d25a",
   "metadata": {},
   "source": [
    "## 9. Read Short CoNLL Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8a70a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading short CoNLL files...\n",
      "Found 808 short CoNLL files in 2.17_short\n",
      "Total short files: 808\n",
      "Languages with short files: 187\n"
     ]
    }
   ],
   "source": [
    "# Read short files\n",
    "print(\"Reading short CoNLL files...\")\n",
    "langShortConllFiles, allshortconll = conll_processing.read_shorter_conll_files(langConllFiles, UD_VERSION)\n",
    "\n",
    "total_short_files = sum(len(files) for files in langShortConllFiles.values())\n",
    "print(f\"Total short files: {total_short_files}\")\n",
    "print(f\"Languages with short files: {len(langShortConllFiles)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2ee000",
   "metadata": {},
   "source": [
    "## 10. Export Metadata\n",
    "\n",
    "Save all metadata and file lists for use in subsequent notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78e244e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved metadata to data/metadata.pkl\n",
      "Metadata saved to data/metadata.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save metadata\n",
    "metadata = {\n",
    "    'langConllFiles': langConllFiles,\n",
    "    'langShortConllFiles': langShortConllFiles,\n",
    "    'langNames': langNames,\n",
    "    'langnameGroup': langnameGroup,\n",
    "    'group2lang': group2lang,\n",
    "    'appearance_dict': appearance_dict,\n",
    "    'ud_version': UD_VERSION\n",
    "}\n",
    "\n",
    "data_utils.save_metadata(metadata, os.path.join(DATA_DIR, 'metadata.pkl'))\n",
    "print(f\"Metadata saved to {DATA_DIR}/metadata.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7910d59",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has:\n",
    "- ✅ Loaded UD treebanks v2.17\n",
    "- ✅ Connected to Google Sheets for language metadata\n",
    "- ✅ Validated language codes and groups\n",
    "- ✅ Computed basic statistics (files, sentences, tokens)\n",
    "- ✅ Created short CoNLL files for parallel processing\n",
    "- ✅ Exported metadata for downstream notebooks\n",
    "\n",
    "**Next step**: Run `02_dependency_analysis.ipynb` to compute dependency size metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c08ac7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75f324a2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
